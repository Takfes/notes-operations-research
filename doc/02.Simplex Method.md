## Simplex Method

**Standard Form**: Before applying the simplex method, the linear programming problem should be put into the canonical or standard form. In standard form, a linear programming problem has the following structure:

Objective Function: The problem seeks to maximize the objective function. If the original problem is a minimization problem, it can be converted to a maximization problem by multiplying the objective function by -1.

Constraints: All constraints are expressed as linear equations (i.e., they're equalities). If the original problem has inequality constraints, slack or surplus variables are added to convert them into equalities.

Non-negativity Condition: All decision variables are non-negative.

---

**Simplex Method Steps**: Here's a high-level overview of how the simplex method works:

Step 1 - Initialization: Begin with a feasible solution. This is usually obtained by setting all decision variables to zero, and the value of the slack/surplus variables is equal to the right-hand side of the corresponding constraint.

Step 2 - Optimality Check: Check if the current solution is optimal. This is done by examining the coefficients of the non-basic variables in the objective function row of the simplex table. If all coefficients are non-positive, then the current solution is optimal.

Step 3 - Pivot Operation: If the current solution isn't optimal, choose a non-basic variable with a positive coefficient in the objective function row to become a basic variable (entering variable). This is usually done using the largest coefficient rule or the first positive rule.

Step 4 - Feasibility Check: Choose a basic variable to become non-basic (leaving variable). This is done by performing the minimum ratio test.

Step 5 - Iteration: Update the simplex table by performing row operations to pivot on the element at the intersection of the entering variable column and the leaving variable row. Repeat Steps 2-5 until an optimal solution is found.

---

**Simplex Method Key Notions**

- **Slack and Excess Variables**: These are auxiliary variables added to linear programming problems to convert inequalities into equalities, which are easier to work with.

- **Slack Variables**: When you have a less-than-or-equal-to constraint (`≤`), you add a slack variable to the left-hand side of the constraint to make it an equality. Slack variables can be thought of as the unused resources in an inequality constraint. For example, if you have a constraint like `2x + 3y ≤ 5`, you would add a slack variable `s` to get `2x + 3y + s = 5`, where `s ≥ 0`.

- **Excess Variables**: These are similar to slack variables but are used for greater-than-or-equal-to constraints (`≥`). In this case, you subtract an excess variable from the left-hand side to make the constraint an equality. Excess variables can be thought of as the amount by which a constraint is exceeded.

- **Artificial Variables**: These are variables added to a problem to obtain an initial feasible solution, which is necessary for starting the simplex method. Artificial variables are introduced into constraints where there's no obvious way to create an initial feasible solution. They're usually removed from the problem after obtaining an initial solution.

- **Big M Method**: This is a method used in linear programming to handle constraints of the type `≥` or `=` in the simplex method, which requires an initial feasible solution. The Big M Method introduces artificial variables with a very large penalty (M) to the objective function. This penalty ensures that these variables will be removed from the final solution, as the goal of an optimization problem is to minimize (or maximize) the objective function.

The basic steps in the Big M method are:

- For each constraint where an artificial variable is needed, add the artificial variable to the constraint to make it an equality.

- In the objective function, add a term `-M * artificial_variable` (for a maximization problem) or `+M * artificial_variable` (for a minimization problem).

- Use the simplex method to solve the modified problem. The large penalty associated with the artificial variables will drive their values to zero if a feasible solution exists.
